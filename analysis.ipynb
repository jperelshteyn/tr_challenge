{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import tree\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pysentiment\n",
    "import pymysql\n",
    "import os\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "def get_remote_db_context():\n",
    "    return pymysql.connect(user='admin', password='tr001', host='ECSC00104617.epam.com', database='tr_news_max_challenge')\n",
    "\n",
    "def add_field(df, field, new_field, transformer):\n",
    "    df[new_field] = df[field].apply(transformer)\n",
    "\n",
    "def add_field_length(df, field, new_field, sep=None): \n",
    "    count = lambda val: len(val.split(sep) if sep else val) if not pd.isnull(val) else 0\n",
    "    add_field(df, field, new_field, count)\n",
    "\n",
    "\n",
    "def orig_data(table):\n",
    "    df = None\n",
    "    try:\n",
    "        df = pd.read_pickle('D:\\\\thomson_reuters\\\\data_sets\\\\sql_cache_{0}.pkl'.format(table))\n",
    "    except IOError:\n",
    "        cnx =  get_remote_db_context()\n",
    "        query = '''\n",
    "            select _guid, orgs, body, topics, title\n",
    "            from {0};\n",
    "        '''.format(table)\n",
    "        df = pd.read_sql(query, cnx)\n",
    "\n",
    "        add_field_length(df, 'orgs', 'org_count', ' ')\n",
    "        add_field_length(df, 'body', 'story_word_count', ' ')\n",
    "        add_field_length(df, 'topics', 'topics_count', ' ')\n",
    "        add_field_length(df, 'title', 'title_word_count', ' ')\n",
    "\n",
    "        df.to_pickle('D:\\\\thomson_reuters\\\\data_sets\\\\sql_cache_{0}.pkl'.format(table))\n",
    "        \n",
    "    return df\n",
    "\n",
    "def get_df(file_name, sep, key):\n",
    "    data_folder = 'd:\\\\thomson_reuters\\\\data_sets\\\\'\n",
    "    path = os.path.join(data_folder, file_name)\n",
    "    df = pd.read_csv(path, sep=sep).rename(columns={key: '_guid'})\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_sentiment(df):\n",
    "\n",
    "    df['body_front'] = df['body'].apply(lambda s: s[:500])\n",
    "    \n",
    "#     lm = pysentiment.LM()\n",
    "#     for sentiment in ('Polarity', 'Positive', 'Negative', 'Subjectivity'):\n",
    "#         py_senti = lambda s: 0 if pd.isnull(s) else lm.get_score(lm.tokenize(s))[sentiment]\n",
    "#         df['py_title_' + sentiment] = df['title'].apply(py_senti)\n",
    "#         df['py_body_' + sentiment] = df['body_front'].apply(py_senti)\n",
    "\n",
    "#     tb_polarity_senti = lambda s: TextBlob(s).sentiment[0]\n",
    "#     tb_subjectivity_senti = lambda s: TextBlob(s).sentiment[1]\n",
    "\n",
    "#     df['tb_body_polarity'] = df['body_front'].apply(tb_polarity_senti)\n",
    "#     df['tb_body_subjectivity'] = df['body_front'].apply(tb_subjectivity_senti)\n",
    "#     df['tb_title_polarity'] = df['title'].apply(tb_polarity_senti)\n",
    "#     df['tb_title_subjectivity'] = df['title'].apply(tb_subjectivity_senti)\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    for sentiment in ('compound', 'neg', 'neu', 'pos'):\n",
    "        nltk_senti = lambda s: sia.polarity_scores(s)[sentiment]\n",
    "        df['sentiment_' + sentiment] = df['body_front'].apply(nltk_senti)\n",
    "\n",
    "    df.drop('body_front', axis=1, inplace=True)\n",
    "    \n",
    "def add_features(df):\n",
    "\n",
    "        add_field(df, 'significance', 'is_significant', lambda x: 0 if x == 0 else 1)\n",
    "        add_field(df, 'significance', 'is_very_significant', lambda x: 1 if x == 2 else 0)\n",
    "        add_field(df, 'date.time', 'hour', lambda x: datetime.datetime.fromtimestamp(int(x)).hour)\n",
    "        add_sentiment(df)\n",
    "\n",
    "\n",
    "    \n",
    "def get_working_df(df_type, refresh=False):\n",
    "    if refresh:\n",
    "        df_orig_data = orig_data('labeled_{0}'.format(df_type))\n",
    "        df_orig_data.drop('topics', axis=1, inplace=True)\n",
    "        df_tokens = get_df('token_tfidf_{0}.csv'.format(df_type), '\\t', '_guid')\n",
    "        df_tokens.drop('title', axis=1, inplace=True)\n",
    "        df_bgrams = get_df('bi_gram_tfidf_{0}.csv'.format(df_type), ',', '_guid')\n",
    "        df_bgrams.drop('source.significance', axis=1, inplace=True)        \n",
    "        df_topics = get_df('topics_tfidf_{0}.csv'.format(df_type), ',', 'id')\n",
    "        df_topics.drop('topics', axis=1, inplace=True)\n",
    "        df = pd.merge(df_tokens, df_orig_data, on='_guid', how='inner')\n",
    "        df = pd.merge(df, df_bgrams, on='_guid', how='inner')\n",
    "        df = pd.merge(df, df_topics, on='_guid', how='inner')\n",
    "        add_features(df)\n",
    "        df.drop(['_data_source','_id', 'title', 'Unnamed: 0','source.significance','orgs', 'body',\n",
    "                 'date.time','journal.code','organizations','persons'], axis=1, inplace=True)\n",
    "#         df.drop('_guid', axis=1, inplace=True)\n",
    "        df = df[list(set(df.columns))]\n",
    "        df.to_pickle('D:\\\\thomson_reuters\\\\data_sets\\\\working_dataframe_{0}.pkl'.format(df_type))\n",
    "        return df\n",
    "    else:\n",
    "        return pd.read_pickle('D:\\\\thomson_reuters\\\\data_sets\\\\working_dataframe_{0}.pkl'.format(df_type))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = get_working_df('train', True)\n",
    "df_test = get_working_df('test', True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['_guid', 'sentiment_pos', 'sentiment_neg', 'sentiment_neu', 'sentiment_compound', 'story_word_count', 'topics_count', 'title_word_count', 'org_count']\n",
    "\n",
    "df_test[columns].to_csv('add_features_test.csv', sep=',', quoting=csv.QUOTE_ALL)\n",
    "df_train[columns].to_csv('add_features_train.csv', sep=',', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_guid</th>\n",
       "      <th>sentiment_pos</th>\n",
       "      <th>sentiment_neg</th>\n",
       "      <th>sentiment_neu</th>\n",
       "      <th>sentiment_compound</th>\n",
       "      <th>story_word_count</th>\n",
       "      <th>topics_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>org_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I003a0090e9d311e49ce48b4c25b70f44</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I0064c650f00311e48ec8ed0cb568cff3</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>647</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I008ce4f0f04911e490899ddc8face275</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.926</td>\n",
       "      <td>-0.1280</td>\n",
       "      <td>462</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I009bc470a3b311e5ac01b95a1193ecad</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>1894</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I00d18ee0f02411e4bf7bbb192cc48d22</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.9001</td>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               _guid  sentiment_pos  sentiment_neg  \\\n",
       "0  I003a0090e9d311e49ce48b4c25b70f44          0.158          0.000   \n",
       "1  I0064c650f00311e48ec8ed0cb568cff3          0.131          0.039   \n",
       "2  I008ce4f0f04911e490899ddc8face275          0.035          0.040   \n",
       "3  I009bc470a3b311e5ac01b95a1193ecad          0.104          0.029   \n",
       "4  I00d18ee0f02411e4bf7bbb192cc48d22          0.159          0.000   \n",
       "\n",
       "   sentiment_neu  sentiment_compound  story_word_count  topics_count  \\\n",
       "0          0.842              0.8779               336             1   \n",
       "1          0.831              0.7579               647             2   \n",
       "2          0.926             -0.1280               462             2   \n",
       "3          0.867              0.6249              1894             1   \n",
       "4          0.841              0.9001               616             1   \n",
       "\n",
       "   title_word_count  org_count  \n",
       "0                10          0  \n",
       "1                 2          0  \n",
       "2                 3          0  \n",
       "3                 5          0  \n",
       "4                15          0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "\tis_significant\n",
      "N =  8081\n",
      "\t\tAccuracy:  0.898572131955 \tF1:  0.92832289492\n",
      "\tis_very_significant\n",
      "N =  5872\n",
      "\t\tAccuracy:  0.804158283032 \tF1:  0.754208754209\n",
      "TR score 8.27474150665\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.774495322501 \tF1:  0.775528657199\n",
      "LogisticRegression\n",
      "\tis_significant\n",
      "N =  8037\n",
      "\t\tAccuracy:  0.88578313253 \tF1:  0.915688367129\n",
      "\tis_very_significant\n",
      "N =  5477\n",
      "\t\tAccuracy:  0.795486600846 \tF1:  0.77093206951\n",
      "TR score 8.16192771084\n",
      "DecisionTreeClassifier\n",
      "\tis_significant\n",
      "N =  8004\n",
      "\t\tAccuracy:  0.828747628083 \tF1:  0.881289049655\n",
      "\tis_very_significant\n",
      "N =  6187\n",
      "\t\tAccuracy:  0.79704797048 \tF1:  0.746932515337\n",
      "TR score 7.65891840607\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.679316888046 \tF1:  0.683377243491\n",
      "RandomForestClassifier\n",
      "\tis_significant\n",
      "N =  8097\n",
      "\t\tAccuracy:  0.888337468983 \tF1:  0.918743228602\n",
      "\tis_very_significant\n",
      "N =  5399\n",
      "\t\tAccuracy:  0.795325779037 \tF1:  0.75611814346\n",
      "TR score 8.17320099256\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.754838709677 \tF1:  0.755260544497\n",
      "AdaBoostClassifier\n",
      "\tis_significant\n",
      "N =  8088\n",
      "\t\tAccuracy:  0.876976284585 \tF1:  0.909024479357\n",
      "\tis_very_significant\n",
      "N =  5724\n",
      "\t\tAccuracy:  0.791161796151 \tF1:  0.748065348237\n",
      "TR score 8.09140316206\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.731225296443 \tF1:  0.733244672197\n",
      "KNeighborsClassifier\n",
      "\tis_significant\n",
      "N =  8082\n",
      "\t\tAccuracy:  0.87684729064 \tF1:  0.907612712491\n",
      "\tis_very_significant\n",
      "N =  5464\n",
      "\t\tAccuracy:  0.788533134773 \tF1:  0.756432246998\n",
      "TR score 8.09014778325\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.735467980296 \tF1:  0.732373644006\n",
      "SVC\n",
      "\tis_significant\n",
      "N =  8071\n",
      "\t\tAccuracy:  0.863302302793 \tF1:  0.907890392869\n",
      "\tis_very_significant\n",
      "N =  5677\n",
      "\t\tAccuracy:  0.735257985258 \tF1:  0.693238434164\n",
      "TR score 7.59039686428\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.698187163155 \tF1:  0.700169429567\n",
      "LinearSVC\n",
      "\tis_significant\n",
      "N =  8093\n",
      "\t\tAccuracy:  0.581971272907 \tF1:  0.558115183246\n",
      "\tis_very_significant\n",
      "N =  2279\n",
      "\t\tAccuracy:  0.753153153153 \tF1:  0.717525773196\n",
      "TR score 5.52947003467\n",
      "\tsignificant_cats\n",
      "\t\tAccuracy:  0.723130262506 \tF1:  0.718850518437\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "df_main = get_working_df('train')\n",
    "\n",
    "sig_tokens = set([t for t, c in pickle.load(open('data\\\\token_freqs.pkl', mode='r'))])\n",
    "sig_bgs = set([bg for bg, c in pickle.load(open('data\\\\bi_gram_freqs.pkl', mode='r'))])\n",
    "other_features = set(['nltk_body_compound', 'nltk_body_neg', 'nltk_body_neu', 'nltk_body_pos', \n",
    "                      'org_count','story_word_count','topics_count', 'title_word_count', 'hour'])\n",
    "\n",
    "sig_features = sig_tokens | sig_bgs | other_features\n",
    "\n",
    "\n",
    "y_cols = ['significance', 'is_significant', 'is_very_significant']\n",
    "x_cols = [c for c in df_main.columns if c not in y_cols and c in sig_features]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    GradientBoostingClassifier(),\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    KNeighborsClassifier(n_neighbors=3, metric='cosine', algorithm='brute'),\n",
    "    SVC(),\n",
    "    LinearSVC(loss='hinge'),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def tt_split(df):\n",
    "    msk = np.random.rand(len(df)) < 0.8\n",
    "    df_test = df[~msk]\n",
    "    df_train = df[msk]\n",
    "\n",
    "    return df_train, df_test\n",
    "    \n",
    "\n",
    "def test_classifier(clf, df_train, df_test, x_cols, y_col, average_type):\n",
    "    X_test, y_test = df_test[x_cols], df_test[y_col]\n",
    "    X_train, y_train = df_train[x_cols], df_train[y_col]\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score(y_pred, y_test, average_type)\n",
    "    return model, y_pred, y_test\n",
    "\n",
    "def score(y_pred, y_test, average_type):\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=average_type)\n",
    "    print '\\t\\tAccuracy: ', score, '\\t', 'F1: ', f1\n",
    "\n",
    "\n",
    "for clf in classifiers:\n",
    "\n",
    "    df = df_main[x_cols + y_cols].dropna()\n",
    "\n",
    "    df_train, df_test = tt_split(df)\n",
    "    \n",
    "    N = len(df_train)\n",
    "    \n",
    "    df = None\n",
    "\n",
    "    model_name = str(clf).split('(')[0]\n",
    "\n",
    "    print model_name\n",
    "    print '\\tis_significant'\n",
    "    print 'N = ', N\n",
    "    \n",
    "    sig_model, y_pred_s, y_test_s = test_classifier(clf, df_train, df_test, x_cols, 'is_significant', 'binary')\n",
    "\n",
    "    def sig_score(scores):\n",
    "        pred_s, real = scores\n",
    "        if pred_s == 0:\n",
    "            if real == 0:\n",
    "                return 10\n",
    "            elif real == 1:\n",
    "                return 3\n",
    "            else:\n",
    "                return -3\n",
    "        else:\n",
    "            return None\n",
    "            \n",
    "    ns_tr_score = [s for s in map(sig_score, zip(y_pred_s, df_test['significance'])) if s]\n",
    "\n",
    "    y_train_pred_s = sig_model.predict(df_train[x_cols])\n",
    "    \n",
    "    pred_train_s_mask = map(lambda x: x == 1, y_train_pred_s)\n",
    "    pred_test_s_mask = map(lambda x: x == 1, y_pred_s)\n",
    "    \n",
    "    df_sig_train = df_train[pred_train_s_mask]\n",
    "    df_sig_test = df_test[pred_test_s_mask]\n",
    "\n",
    "    print '\\tis_very_significant'\n",
    "    print 'N = ', len(df_sig_train)      \n",
    "\n",
    "    vsig_model, y_pred_vs, y_test_vs = test_classifier(clf, df_sig_train, df_sig_test, x_cols, 'is_very_significant', 'binary')\n",
    "\n",
    "    def very_sig_score(scores):\n",
    "        pred_vs, real = scores\n",
    "        if pred_vs == 1:\n",
    "            if real == 2:\n",
    "                return 10\n",
    "            elif real == 1:\n",
    "                return 3\n",
    "            else:\n",
    "                return -3\n",
    "        else:\n",
    "            if real == 1:\n",
    "                return 10\n",
    "            else:\n",
    "                return 3            \n",
    "    \n",
    "    s_tr_score = map(very_sig_score ,zip(y_pred_vs, df_sig_test['significance']))\n",
    "\n",
    "    print 'TR score', (sum(ns_tr_score) + sum(s_tr_score)) / (len(ns_tr_score) + len(s_tr_score))\n",
    "    \n",
    "    if model_name != 'LogisticRegression':\n",
    "        print '\\tsignificant_cats'\n",
    "        cat_model, y_pred, y_test = test_classifier(clf, df_train, df_test, x_cols, 'significance', 'weighted')\n",
    "\n",
    "    clf = None\n",
    "#y_cat_pred = pred[0].combine(pred[1], lambda s, vs: 0 if s == 0 else (2 if vs == 1 else 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(list([1,2,43,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = pd.Series([-1 for _ in xrange(5)])\n",
    "s2 = pd.Series([1,2,3,2,5])\n",
    "\n",
    "s1 = (s1 + s2).apply(lambda x: x)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('D:\\\\thomson_reuters\\\\data_sets\\\\token_tfidf_training.csv', sep='\\t')\n",
    "df_test = pd.read_csv('D:\\\\thomson_reuters\\\\data_sets\\\\token_tfidf_testing.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'announcements_', 'fortnight', 'nta', 'steepest', 'stoc', 'summat', 'vwp'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39166666666666666"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pysentiment\n",
    "from textblob import TextBlob\n",
    "\n",
    "def add_sentiment(df):\n",
    "\n",
    "    df['body_front'] = df['body'].apply(lambda s: s[:200])\n",
    "    \n",
    "    for sentiment in ('Polarity', 'Positive', 'Negative', 'Subjectivity'):\n",
    "        py_senti = lambda s: 0 if pd.isnull(s) else lm.get_score(lm.tokenize(s))[sentiment]\n",
    "        df['py_title_' + sentiment] = df['title'].apply(py_senti)\n",
    "        df['py_body_' + sentiment] = df['body_front'].apply(py_senti)\n",
    "\n",
    "    tb_polarity_senti = lambda s: TextBlob(s).sentiment[0]\n",
    "    tb_subjectivity_senti = lambda s: TextBlob(s).sentiment[1]\n",
    "\n",
    "    df['tb_body_polarity'] = df['body_front'].apply(tb_polarity_senti)\n",
    "    df['tb_body_subjectivity'] = df['body_front'].apply(tb_subjectivity_senti)\n",
    "    df['tb_title_polarity'] = df['title'].apply(tb_polarity_senti)\n",
    "    df['tb_title_subjectivity'] = df['title'].apply(tb_subjectivity_senti)\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    for sentiment in ('compound', 'neg', 'neu', 'pos'):\n",
    "        nltk_senti = lambda s: sia.polarity_scores(s)[sentiment]\n",
    "        df['nltk_title_' + sentiment] = df['title'].apply(nltk_senti)\n",
    "        df['nltk_body_' + sentiment] = df['body_front'].apply(nltk_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = lambda x: datetime.datetime.fromtimestamp(int(x)).hour\n",
    "\n",
    "dt('1430439473')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
